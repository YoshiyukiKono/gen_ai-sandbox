{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlCMGooLGr8fqaRRgh+Wrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoshiyukiKono/gen_ai-sandbox/blob/main/langchain_chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://book.st-hakky.com/docs/chains-of-langchain/"
      ],
      "metadata": {
        "id": "xlv-blZsOvjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJC8e9r8Ou3-",
        "outputId": "a48931cb-a4f2-4b00-a044-297732754f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.288-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.37-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.288 langsmith-0.0.37 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnTo-fGtO9VE",
        "outputId": "b4507d5f-f1a8-469e-a8ea-a76743eabb92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/76.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMNEExOXPDXD",
        "outputId": "d49cda84-166f-44a2-bee8-1efce613bbcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqSD2b0uPejT",
        "outputId": "f6af1813-c30a-4f0c-9f30-1ec87c4edf93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm ラッパーのインポート\n",
        "from langchain import OpenAI\n",
        "# プロンプトテンプレートのインポート\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# LLMChain に加えて SimpleSequentialChain もインポートする\n",
        "# SimpleSequentialChain は、複数のチェーンを連続実行するためのチェーンで以下の特徴をもつ\n",
        "# - 各ステップの入出力は一つ\n",
        "# - 各ステップの出力が次のステップの入力になる\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# llm ラッパーの初期化\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# 最初のプロンプトテンプレートの作成\n",
        "prompt_first = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"{product}を作る会社の社名として、何かいいものはないですか？日本語の社名でお願いします。\",\n",
        ")\n",
        "\n",
        "# 最初に実行する LLM チェーンを定義\n",
        "# 会社名を考えてもらう\n",
        "chain_first = LLMChain(llm=llm, prompt=prompt_first)\n",
        "\n",
        "# 次のプロンプトテンプレートの作成\n",
        "prompt_second = PromptTemplate(\n",
        "    input_variables=[\"company_name\"],\n",
        "    template=\"{company_name}という会社名の企業のキャッチコピーを考えてください。\",\n",
        ")"
      ],
      "metadata": {
        "id": "n6JtYmZvPGyU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 次に実行する LLM チェーンを定義\n",
        "# キャッチコピーを考えてもらう\n",
        "chain_second = LLMChain(llm=llm, prompt=prompt_second)\n",
        "\n",
        "# 二つの LLM チェーンを連結\n",
        "overall_chain = SimpleSequentialChain(chains=[chain_first, chain_second], verbose=True)\n",
        "\n",
        "# 連結してできたチェーンを実行\n",
        "chatchphrase = prediction = overall_chain.run(\"カラフルな靴下\")\n",
        "print(chatchphrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZM2kyewPNh1",
        "outputId": "206d0f3c-e5fa-4f78-d23a-0f1146273ec1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "「カラフルソックス工房」\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "「足元を彩る、カラフルソックス工房」\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "「足元を彩る、カラフルソックス工房」\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "# LLMChain のインポート\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# カスタムチェーンを定義するために Chain クラスをインポート\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "\n",
        "# このチェーンは、２つの LLMChain の出力を連結する\n",
        "class ConcatenateChain(Chain):\n",
        "    # もととなる２つの LLMChain をコンストラクタで受け取る\n",
        "    chain_1: LLMChain\n",
        "    chain_2: LLMChain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        # ２つのチェーンの入力キーの和集合\n",
        "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
        "        return list(all_input_vars)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        # このチェーンの出力キーは、concat_output のみ\n",
        "        return ['concat_output']\n",
        "\n",
        "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
        "        # `output_keys` で定義したキーをもつ Dict を返す関数を定義する\n",
        "        # ここでは、２つのチェーンを独立に実行した得られた出力を連結して返す\n",
        "        output_1 = self.chain_1.run(inputs)\n",
        "        output_2 = self.chain_2.run(inputs)\n",
        "        return {'concat_output': output_1 + output_2}\n",
        "\n"
      ],
      "metadata": {
        "id": "qkSWzMVFPotS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm ラッパーのインポート\n",
        "from langchain import OpenAI\n",
        "# LLM チェーンの構築で必要なプロンプトテンプレートのインポート\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# llm ラッパーの初期化\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "prompt_1 = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"{product}を作る会社の社名として、何かいいものはないですか？日本語の社名でお願いします。\",\n",
        ")\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"{product}を作る会社のスローガンとして、何かいいものはないですか？日本語でお願いします。\",\n",
        ")\n",
        "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
        "concat_output = concat_chain.run(\"カラフルな靴下\")\n",
        "print(f\"Concatenated output:\\n{concat_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wlm2yXbPwt6",
        "outputId": "8aff81d4-85f9-48ea-e7e0-fb7e84f90648"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated output:\n",
            "\n",
            "\n",
            "「カラフルソックス工房」\n",
            "\n",
            "「足元を彩る、カラフルな靴下」\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/modules/chains/\n",
        "\n",
        "## Async API\n",
        "https://python.langchain.com/docs/modules/chains/how_to/async_chain"
      ],
      "metadata": {
        "id": "11e_dylaQCDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import time\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "def generate_serially():\n",
        "    llm = OpenAI(temperature=0.9)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"product\"],\n",
        "        template=\"What is a good name for a company that makes {product}?\",\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    for _ in range(5):\n",
        "        resp = chain.run(product=\"toothpaste\")\n",
        "        print(resp)\n",
        "\n",
        "\n",
        "async def async_generate(chain):\n",
        "    resp = await chain.arun(product=\"toothpaste\")\n",
        "    print(resp)\n",
        "\n",
        "\n",
        "async def generate_concurrently():\n",
        "    llm = OpenAI(temperature=0.9)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"product\"],\n",
        "        template=\"What is a good name for a company that makes {product}?\",\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    tasks = [async_generate(chain) for _ in range(5)]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "s = time.perf_counter()\n",
        "# If running this outside of Jupyter, use asyncio.run(generate_concurrently())\n",
        "await generate_concurrently()\n",
        "elapsed = time.perf_counter() - s\n",
        "print(\"\\033[1m\" + f\"Concurrent executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
        "\n",
        "s = time.perf_counter()\n",
        "generate_serially()\n",
        "elapsed = time.perf_counter() - s\n",
        "print(\"\\033[1m\" + f\"Serial executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srGwvLbqPzUi",
        "outputId": "d95d13db-720c-4a7f-8338-eb32f9a1e888"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Brightshine Toothpaste.\n",
            "\n",
            "\n",
            "SmileFresh.\n",
            "\n",
            "\n",
            "PearlySmiles Toothpaste Co.\n",
            "\n",
            "\n",
            "BrightSmile Toothpaste Company\n",
            "\n",
            "\n",
            "BrightSmile Toothpaste Co.\n",
            "\u001b[1mConcurrent executed in 0.76 seconds.\u001b[0m\n",
            "\n",
            "\n",
            "SparkleSmile Toothpaste.\n",
            "\n",
            "\n",
            "Brush Bright Toothpaste.\n",
            "\n",
            "\n",
            "SmileGlow Toothpaste\n",
            "\n",
            "\n",
            "MintySmile Toothpaste Co.\n",
            "\n",
            "\n",
            "Bright Smile Fresheners\n",
            "\u001b[1mSerial executed in 3.36 seconds.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1WawIm_QOIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}