{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoshiyukiKono/gen_ai-sandbox/blob/main/langchain-pdf-simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
      ],
      "metadata": {
        "id": "YODRRq-0Y4Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "oX33RRkrY2WY",
        "outputId": "7e0feb6f-d7ec-41c3-b17c-789c62ac741b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/277.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/277.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMMMfJaKo4Ww",
        "outputId": "9e180a2a-08c5-42ca-d4bc-cf06812bb300"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
            "  Downloading langsmith-0.0.57-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.330 langsmith-0.0.57 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./2302.00618.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "uqx1XkeMZCMd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "QzK8Pk4RZY5I",
        "outputId": "cc10a765-9792-4276-a744-ad877c3b66cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\\nLanguage Models\\nZhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\\nAbstract\\nLarge language models can perform various rea-\\nsoning tasks by using chain-of-thought prompting,\\nwhich guides them to ﬁnd answers through step-\\nby-step demonstrations. However, the quality of\\nthe prompts depends on the demonstrations given\\nto the models, and creating many of them by hand\\nis costly. We introduce S YNTHETIC PROMPTING ,\\na method that leverages a few handcrafted exam-\\nples to prompt the model to generate more exam-\\nples by itself, and selects effective demonstrations\\nto elicit better reasoning. Our method alternates\\nbetween a backward and forward process to gen-\\nerate new examples. The backward process gen-\\nerates a question that match a sampled reasoning\\nchain, so that the question is solvable and clear.\\nThe forward process produces a more detailed\\nreasoning chain for the question, improving the\\nquality of the example. We evaluate our method\\non numerical, symbolic, and algorithmic reason-\\ning tasks, and show that it outperforms existing\\nprompting techniques.\\n1. Introduction\\nFew-shot demonstrations, i.e., examples of inputs and out-\\nputs for a task, can enable Large Language Models (LLMs)\\nto perform various tasks without ﬁne-tuning (Brown et al.,\\n2020; Chung et al., 2022). LLMs can further improve their\\nperformance by using chain-of-thought prompting, which\\nprovides intermediate reasoning steps for the task (Wei et al.,\\n2022b; Kojima et al., 2022). However, the LLMs’ few-shot\\nperformance depends heavily on the quality of the demon-\\nstrations, especially for reasoning tasks that need complex\\nand diverse reasoning patterns. Manually creating a large\\nand diverse set of examples for demonstration selection is\\ncostly and tedious, while relying on a limited set of demon-\\nstrations may hamper the LLMs’ generalization and adapta-\\n1Tsinghua University2This work was done during an internship\\nin MSRA3Microsoft Research Asia4Microsoft. Correspondence\\nto: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\\nIn this paper, we propose a novel method, S YNTHETIC\\nPROMPTING , that leverages the LLMs’ own knowledge and\\ngenerative power to augment a limited set of demonstra-\\ntions with self-synthesized examples, and then uses the aug-\\nmented set to elicit better reasoning in the LLMs. Specif-\\nically, given a few seed examples, each consisting of a\\nquestion and a chain of reasoning steps, we prompt an\\nLLM to generate more examples by alternating between\\ntwo processes: (1) the backward process, where the LLM\\nsynthesizes a question based on a self-generated reasoning\\nchain, which ensures that the question is answerable and\\nwell-deﬁned; and (2) the forward process, where the LLM\\nproduces a reasoning chain for the synthesized question,\\nwhich reﬁnes the reasoning chain to be more precise and\\nconsistent with the question. We repeat this process until\\nwe obtain enough synthetic examples. To select the most\\neffective demonstrations from the augmented set, we pro-\\npose a new selection scheme based on in-cluster complexity,\\nwhich aims to maximize the diversity and informativeness\\nof the demonstrations by clustering them and choosing the\\nmost complex one (the one with the longest reasoning chain)\\nfrom each cluster. Finally, we prompt the LLM with the\\nselected demonstrations to generate a reasoning chain for a\\ntest question and then use it to obtain the answer.\\nWe evaluate our method on various reasoning tasks, in-\\ncluding numerical reasoning, algorithmic reasoning, and\\nsymbolic reasoning. Following previous few-shot settings\\n(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\\nthat our method can signiﬁcantly improve the LLMs’ per-\\nformance, achieving up to 15.6% absolute gains over the\\nstate-of-the-art methods.\\nOur main contributions are:\\n•We introduce S YNTHETIC PROMPTING , a novel\\nmethod that augments a limited set of demonstrations', metadata={'source': './2302.00618.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Astra DB Template\n",
        "\n",
        "## Environment Setup\n",
        "It is expected to use GPU when using the embedding model. Change the setting from the menu as follows: Runtime > Change runtime type > Hardware accelerator: `GPU`"
      ],
      "metadata": {
        "id": "5GmUfFL0YCtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O secure-connect-vector.zip \"https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/216b7807-e6c4-471d-bb29-342090dcbade-1/secure-connect-vector.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231106%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231106T065208Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=51abe7d08f0304313f9a2c3848b0a5a9c9b4df3edf4a38d0565633b34e3a4ba4\""
      ],
      "metadata": {
        "id": "IUm51RWBJiU9",
        "outputId": "156dc24e-d17b-44f5-8971-032a91e0efa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-06 06:52:20--  https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/216b7807-e6c4-471d-bb29-342090dcbade-1/secure-connect-vector.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231106%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231106T065208Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=51abe7d08f0304313f9a2c3848b0a5a9c9b4df3edf4a38d0565633b34e3a4ba4\n",
            "Resolving datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)... 52.219.178.66, 3.5.131.160, 52.219.103.26, ...\n",
            "Connecting to datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)|52.219.178.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12252 (12K) [application/zip]\n",
            "Saving to: ‘secure-connect-vector.zip’\n",
            "\n",
            "secure-connect-vect 100%[===================>]  11.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-06 06:52:20 (194 MB/s) - ‘secure-connect-vector.zip’ saved [12252/12252]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Install"
      ],
      "metadata": {
        "id": "YVipcXhY7QB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Astra"
      ],
      "metadata": {
        "id": "gbIfQ5l_HaJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O secure-connect-demo.zip \"https://...\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3ElhqbHd3G",
        "outputId": "cf33f74f-8741-4b43-e928-e0d581c64c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-01 05:03:54--  https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/d5556151-ea9a-4309-8be3-b8ea2b1cd03d-1/secure-connect-demo.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20230901%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20230901T050340Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=7db1257a20828e206535d85e46ffdfe26c4fe1166781a157033bbaac549b23c3\n",
            "Resolving datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)... 3.5.131.128, 52.219.95.34, 52.219.179.34, ...\n",
            "Connecting to datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)|3.5.131.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12247 (12K) [application/zip]\n",
            "Saving to: ‘secure-connect-demo.zip’\n",
            "\n",
            "secure-connect-demo 100%[===================>]  11.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-01 05:03:54 (119 MB/s) - ‘secure-connect-demo.zip’ saved [12247/12247]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O secure-connect-demo.zip \"https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/d5556151-ea9a-4309-8be3-b8ea2b1cd03d-1/secure-connect-demo.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231002%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231002T050957Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=c59bc8860db40647ef197f48706521316d85aa04692f5e5a11305eb0365f67bd\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZISHX27N1lMe",
        "outputId": "0b9068c9-b518-44fd-f0b0-89e62b4aefa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-02 05:10:07--  https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/d5556151-ea9a-4309-8be3-b8ea2b1cd03d-1/secure-connect-demo.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231002%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231002T050957Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=c59bc8860db40647ef197f48706521316d85aa04692f5e5a11305eb0365f67bd\n",
            "Resolving datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)... 52.219.93.226, 52.219.108.2, 52.219.93.90, ...\n",
            "Connecting to datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)|52.219.93.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12247 (12K) [application/zip]\n",
            "Saving to: ‘secure-connect-demo.zip’\n",
            "\n",
            "secure-connect-demo 100%[===================>]  11.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-02 05:10:08 (179 MB/s) - ‘secure-connect-demo.zip’ saved [12247/12247]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cassandra-driver\n",
        "!pip install cassio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k10ziT0zRYw",
        "outputId": "d87181ec-5aad-4bef-8af3-984839903553"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (1.16.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Installing collected packages: geomet, cassandra-driver\n",
            "Successfully installed cassandra-driver-3.28.0 geomet-0.2.1.post1\n",
            "Collecting cassio\n",
            "  Downloading cassio-0.1.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.28.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (1.23.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from cassio) (2.31.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2023.7.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0->cassio) (8.1.7)\n",
            "Installing collected packages: cassio\n",
            "Successfully installed cassio-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SECURE_CONNECT_BUNDLE_PATH = 'secure-connect-vector.zip'"
      ],
      "metadata": {
        "id": "qGzwcnhfIROt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "ASTRA_CLIENT_ID = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVlMnfyJJVUb",
        "outputId": "39790a52-e901-4b13-fa88-cdb3aeb219bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ASTRA_CLIENT_SECRET = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvKJFm2vJgoU",
        "outputId": "61141f05-5b95-468a-b319-eed3a1302963"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrGG5yAEJpnJ",
        "outputId": "44818411-c140-47a3-dbea-9e7c969ab83c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:95b6d7f5-9bb3-4560-82a9-f8f5e9363502. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:95b6d7f5-9bb3-4560-82a9-f8f5e9363502. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(139583899026768) 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:95b6d7f5-9bb3-4560-82a9-f8f5e9363502> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:95b6d7f5-9bb3-4560-82a9-f8f5e9363502. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-b86be92b8b5f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_KEYSPACE = 'pdf'\n",
        "session.set_keyspace(YOUR_KEYSPACE)\n",
        "session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1ixFaIJ9Mw",
        "outputId": "da182541-304f-4237-9730-19d1504a1845"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.Session at 0x7ef3679ecb50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cassio"
      ],
      "metadata": {
        "id": "HysIkBPJbjtO",
        "outputId": "61be1b83-8963-4871-a8de-e351cdb7d331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cassio in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.28.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (1.23.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from cassio) (2.31.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2023.7.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0->cassio) (8.1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "FCsCyZLJcTgF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "WLkDfg9_dB_l",
        "outputId": "aa1beb58-6e1d-4670-d534-95b905733dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "IeNgg0f1dLkn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/integrations/vectorstores/cassandra"
      ],
      "metadata": {
        "id": "iVdDamz_dQ2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xv2mLw5ece87"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = \"pdf_arxiv\"\n",
        "\n",
        "docsearch = Cassandra.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding_function,\n",
        "    session=session,\n",
        "    keyspace=YOUR_KEYSPACE,\n",
        "    table_name=table_name,\n",
        ")"
      ],
      "metadata": {
        "id": "DatB7b8pdYzV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is chain of thoughts\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "yK39q3wldnBj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0])"
      ],
      "metadata": {
        "id": "TCOdz30sdvAj",
        "outputId": "0ffd6e15-3648-45c9-f724-a6754371a810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL' metadata={'page': '10.0', 'source': './2302.00618.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "Ba7nukJTeCnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "retriever = docsearch.as_retriever()"
      ],
      "metadata": {
        "id": "3Cf1V6q3eE-G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool, create_conversational_retrieval_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.schema import BaseRetriever, Document, SystemMessage"
      ],
      "metadata": {
        "id": "dgVtEjZEe1mI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_chatbot_with_retriever(retriever):\n",
        "    llm = ChatOpenAI(temperature=0, streaming=True)\n",
        "    embedding = OpenAIEmbeddings()\n",
        "\n",
        "    retriever_tool = create_retriever_tool(\n",
        "        retriever, \"this_retrevier\", \"Useful when searching for the information about technologies\")\n",
        "    system_message = \"\"\"\n",
        "    You must use the this_retreiver.\n",
        "    \"\"\"\n",
        "    system_message = f\"{system_message} All the responses should be in Japanese language.\"\n",
        "    message = SystemMessage(content=system_message)\n",
        "    agent_executor = create_conversational_retrieval_agent(\n",
        "        llm=llm, tools=[retriever_tool], system_message=message, verbose=True, max_tokens_limit=500)\n",
        "    return agent_executor"
      ],
      "metadata": {
        "id": "M5flDOxIeOHT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = create_chatbot_with_retriever(retriever)"
      ],
      "metadata": {
        "id": "5Lq42CyifdOy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"チェインオブソートはいつ誕生した\"\n",
        "result = chatbot.invoke({\n",
        "            \"input\": prompt})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "eRvLgozxfrEg",
        "outputId": "a0a54861-0cb5-4f7a-e1d7-7790d4e072e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `this_retrevier` with `チェインオブソート`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL', metadata={'page': '10.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nDatasets Example\\nGSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\\nthe third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\\nof the glue sticks that are not used?\\nColored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\\nbracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\\nitem furthest from the dog leash?\\nRepeat Copy Repeat election to the council three times, but after every other word say cool\\nTable 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\\nFollowing these settings, we assumed access to 2 or 4 ran-\\ndom examples from each dataset by default. For numerical\\nreasoning tasks, we also experimented with the 8 examples\\nthat were manually crafted by Wei et al. (2022b) and were\\nadopted by several following papers (Fu et al., 2022; Wang\\net al., 2022a; Gao et al., 2022b). We also used the P AL-style\\nreasoning chains annotated by Gao et al. (2022b).\\nPrompting baselines without synthesis use all provided gold\\nexamples to construct prompts for inference. S YNTHETIC\\nPROMPTING and its variants synthesize examples using the\\nprovided examples, and select 8 synthetic demonstrations\\nbased on in-cluster complexity, unless stated otherwise.\\nSeed examples and synthetic prompts are provided in the\\nSupplementary Materials.\\n4.3. Baselines\\nDirect Prompting Direct prompting (Brown et al., 2020)\\nprompts LLMs to directly generate answers with demonstra-\\ntions of input-answer pairs.\\nCoT Prompting Chain-of-thought prompting (Wei et al.,\\n2022b) is effective in eliciting reasoning in LLMs, which\\nprompts LLMs to generate natural language reasoning steps\\nfollowed by an answer.\\nPAL Prompting PAL prompting (Gao et al., 2022b), a vari-\\nant of chain-of-thought prompting, improves reasoning with\\nstructured code. Figure 1 (right) provides two examples. It\\ndoes not prompt LLMs to include ﬁnal answers into com-\\npletions; answers are obtained by executing the code. This\\nprompting technique has achieved state-of-the-art results on\\nnumerous reasoning tasks.\\nVanilla S YNTHETIC PROMPTING This is a variant of\\nSYNTHETIC PROMPTING , which differs in that prompts\\nused for question synthesis only consist of questions from\\nseed examples. In other words, new questions are syn-\\nthesized by mimicking seed questions, without any other\\ncondition.4.4. Implementation Details\\nWe adopted P AL-style reasoning chains which are structured\\ncode with comments being natural language reasoning step.\\ntext-davinci-003 version of InstructGPT (Ouyang\\net al., 2022) was used as our backend LLM for both syn-\\nthesis and inference. We used top-p sampling (Holtzman\\net al., 2020) for synthesis with temperature set to 0.7, and\\nused greedy decoding for inference with temperature set to\\n0. All numerical reasoning datasets share one set of seed\\nexamples either randomly sampled from GSM8K (when\\nthe number of seeds is 2 or 4) or from Wei et al. (2022b)\\n(when the number of seeds is 8). For datasets of the other\\ntasks, seeds were randomly sampled from their own datasets.\\nWe annotated seed examples with both CoT-style reasoning\\nchains and P AL-style reasoning chains manually, following\\ntheir annotation protocols. Annotations are provided in the\\nSupplementary Materials. For each set of seed examples, we\\nsynthesized more examples by repeating backward-forward\\nsynthesis for 1,000 times. Target complexities range from\\nthe lowest complexity of seed examples to the highest one\\nplusc;cwas set to 4 for numerical reasoning and 2 on the\\nother datasets. In forward synthesis, the number of reason-\\ning chains sampled for each question was 3. The encoder\\nused for clustering was all-mpnet-base-v2 .\\n4.5. Main Results\\nAs shown by Table 2, S YNTHETIC PROMPTING consistently', metadata={'page': '4.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nconditioned on reasoning chains affects correctness nega-\\ntively; 62.5% are ﬂawed, 80% of which are unanswerable,\\ne.g.,\\nAn image is represented by a 4x4 matrix of integers. Each\\ncell of the matrix contains a single integer between 0 and\\n255. What is the average value of all the integers in the\\nmatrix? .\\nNotably, though we also include target complexities into the\\nprompts when synthesizing questions without conditioned\\non reasoning chains, the resulting questions tend to require\\nless reasoning steps than S YNTHETIC PROMPTING , indi-\\ncating that conditioning on numbered reasoning steps can\\ncontrol reasoning complexities better.\\n4.6.2. S CHEMES OF DEMONSTRATION SELECTION\\nDatasets GSM8K Colored Objects\\n# Seed Examples 2 4 2 4\\nRandom 73.4 73.1 83.0 90.0\\nCluster Centroid 73.1 73.0 91.2 93.6\\nSimilarity 72.9 74.0 87.0 94.2\\nIn-Cluster Similarity 72.9 73.2 89.3 95.4\\nComplexity 74.1 74.3 92.7 97.5\\nIn-Cluster Complexity 74.7 75.3 93.8 97.3\\nTable 5: Accuracies with different schemes of demonstra-\\ntion selection.\\nTo make good use of synthesized examples, having an ef-\\nfecitve selection scheme matters. We evaluated the follow-\\ning 6 selection schemes. (1) Random : randomly selects\\ndemonstrations; (2) Cluster Centroid : selects the example\\nclosest to each cluster centroid; (3) Similarity : retrieves\\nthe most similar examples according to cosine similarity;\\n(4)In-Cluster Similarity : select the most similar example\\nfrom each cluster; (5) Complexity : selects the examples\\nwith the most reasoning steps; (6) In-Cluster Complexity :\\nselects the most complex example from each cluster.\\nTable 5 presents the comparisons. Though most selection\\nschemes achieve better performance than P AL prompting,\\ncomplexity-based selection schemes are the most effective\\non the two reasoning tasks, with some other schemes like\\nRandom lagging far behind. Our proposed In-Cluster Com-\\nplexity outperforms Complexity, showing the beneﬁts of\\nusing diverse and complex demonstrations.\\n4.6.3. S ENSITIVITY TO SEED EXAMPLES\\nTo investigate how sensitive S YNTHETIC PROMPTING is\\nto seed examples, we repeated experiments on another two\\nrandom sets of seed examples. Figure 2 demonstrates our\\nsensitivity analysis. S YNTHETIC PROMPTING consistently\\noutperforms P AL prompting on different runs. However,\\n72.97374.373.572.472.774.172.47475.174.874.8\\n71.572.573.574.575.5\\n2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesGSM8KPAL PromptingVanilla Synthetic PromptingSynthetic Prompting\\n88.685.995.393.294.791.787.491.894.194.495.997.7\\n8588919497100\\n2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesColored ObjectsFigure 2: Sensitivity analysis on GSM8K and Colored Ob-\\njects. We experimented with another two random sets of\\nseed examples of size 2 and 4 for each dataset.\\nwe observed that seed examples with better P AL prompting\\nperformance does not necessarily lead to better S YNTHETIC\\nPROMPTING performance.\\n4.7. Comparison with Selecting from Training\\nExamples\\nTo measure the performance gap between using synthetic\\ndemonstrations and using gold demonstrations from a large\\nset of carefully-curated examples, we selected 8 demon-\\nstrations from the training set of GSM8K with the two\\ncomplexity-based selection schemes (i.e., Complexity and\\nIn-Cluster Complexity in Section 4.6.2), respectively. As\\nthe training examples were annotated with natural language\\nreasoning chains (CoT-style reasoning), we measured the\\nnumbers of natural language reasoning steps as reasoning\\ncomplexities for complexity-based selection, and manu-\\nally annotated selected examples with P AL-style reasoning\\nchains for P AL prompting. As the training examples of\\nGSM8K are diverse, both Complexity and In-Cluster Com-\\nplexity select diverse and informative demonstrations, and\\nyield an accuracy of 77.0% on the test set of GSM8K, sur-\\npassing our accuracy of 75.3% by absolute 1.7%. As shown', metadata={'page': '6.0', 'source': './2302.00618.pdf'}), Document(page_content='of in-context demonstrations. We show that by prompting\\na large language model to synthesize more examples, we\\ncan improve its reasoning performance on numerical, sym-\\nbolic, and algorithmic tasks, compared to existing prompt-\\ning methods such as chain-of-thought prompting and P AL', metadata={'page': '7.0', 'source': './2302.00618.pdf'})]\u001b[0m\u001b[32;1m\u001b[1;3mチェインオブソートに関する記事の執筆日は、2022年のNAACL（Association for Computational Linguistics: Human Language Technologies）で開催された会議の中で発表されたものです。具体的な執筆日は記載されていません。申し訳ありませんが、より具体的な情報を提供することはできません。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "チェインオブソートに関する記事の執筆日は、2022年のNAACL（Association for Computational Linguistics: Human Language Technologies）で開催された会議の中で発表されたものです。具体的な執筆日は記載されていません。申し訳ありませんが、より具体的な情報を提供することはできません。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1NyvFzqjoNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}